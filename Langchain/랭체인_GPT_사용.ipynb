{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 랭체인 주요기능 \n",
    "- 문맥 인식: 언어 모델과 다양한 문맥 소스(프롬프트 지시, 예제, 응답의 근거 내용 등)를 연동하며, 사용자의 문맥을 정확히 이해합니다.\n",
    "- 추론 능력: 제공된 문맥에 기반하여 어떤 대답을 할지, 또는 어떠한 액션을 취할지에 대한 추론이 가능합니다.\n",
    "- 구성 요소: 사용자는 언어 모델과의 상호작용을 위해 다양한 구성 요소와 추상화를 활용할 수 있습니다. 이러한 구성 요소는 개별적으로, 또는 랭체인 프레임워크 내에서 모듈식으로 쉽게 활용할 수 있습니다.\n",
    "- 사용 준비된 체인: 특정 고수준 작업을 수행하기 위해 미리 조립된 구성 요소의 패키지입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install openai langchain dotenv langchain_community"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import openai\n",
    "\n",
    "load_dotenv('../.env')  # .env 파일의 환경변수 로드\n",
    "api_token = os.environ.get(\"OPENAI_API_KEY\")\n",
    "\n",
    "# openai 버전이 1.x.x 이하일경우 \n",
    "\"\"\"\n",
    "openai.api_key = api_token\n",
    "\n",
    "models = openai.Model.list()\n",
    "for model in models['data']:\n",
    "    print(model.id)\n",
    "\"\"\"\n",
    "\n",
    "# openai 버전이 1.x.x 이상일경우 \n",
    "client = openai.OpenAI(api_key=api_token)\n",
    "\n",
    "models = client.models.list()\n",
    "for model in models.data:\n",
    "    print(model.id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "대한민국의 수도는 뭐야? 에 대한 답변 : 대한민국의 수도는 서울입니다.\n"
     ]
    }
   ],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "gpt41 = ChatOpenAI(model=\"gpt-4.1-nano\", temperature=0, max_tokens=100)\n",
    "question = \"대한민국의 수도는 뭐야?\"\n",
    "print(f'{question} 에 대한 답변 : {gpt41.predict(question)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* PromptTemplate  \n",
    "사용자의 입력 변수를 사용하여 완전한 프롬프트 문자열을 만드는 데 사용되는 템플릿입니다  \n",
    "사용법 :  \n",
    "template: 템플릿 문자열입니다. 이 문자열 내에서 중괄호 {}는 변수를 나타냅니다.  \n",
    "input_variables: 중괄호 안에 들어갈 변수의 이름을 리스트로 정의합니다.  \n",
    "\n",
    "* input_variables  \n",
    "input_variables는 PromptTemplate에서 사용되는 변수의 이름을 정의하는 리스트입니다.  \n",
    "사용법: 리스트 형식으로 변수 이름을 정의합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LLMChain 객체\n",
    "LLMChain은 특정 PromptTemplate와 연결된 체인 객체를 생성합니다  \n",
    "\n",
    "사용법  \n",
    "- prompt: 앞서 정의한 PromptTemplate 객체를 사용합니다.\n",
    "- llm: 언어 모델을 나타내며, 이 예시에서는 이미 어딘가에서 정의된 것으로 보입니다.\n",
    "- run() 함수로 템플릿 프롬프트 실행\n",
    "- apply() 함수로 여러개의 입력을 한 번에 실행\n",
    "- generate() 는 문자열 대신에 LLMResult를 반환하는 점을 제외하고는 apply와 유사"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "대한민국의 수도는 서울입니다.\n",
      "미국의 수도는 워싱턴 D.C.입니다.\n"
     ]
    }
   ],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "\n",
    "temp_question = '{country}의 수도는 뭐야?'\n",
    "country_prompt = PromptTemplate(template=temp_question, input_variables=['country'])\n",
    "gpt41_chain = LLMChain(llm=gpt41, prompt=country_prompt)\n",
    "print(gpt41_chain.run(country='대한민국'))\n",
    "print(gpt41_chain.run(country='미국'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "호주의 수도는 캔버라입니다.\n",
      "중국의 수도는 베이징입니다.\n",
      "네덜란드의 수도는 암스테르담입니다.\n"
     ]
    }
   ],
   "source": [
    "input_list = [\n",
    "    {'country': '호주'},\n",
    "    {'country': '중국'},\n",
    "    {'country': '네덜란드'}\n",
    "]\n",
    "\n",
    "output_list =gpt41_chain.apply(input_list)\n",
    "for i in range(len(output_list)):\n",
    "    print(f'{output_list[i][\"text\"]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "호주의 수도는 캔버라입니다.\n",
      "중국의 수도는 베이징입니다.\n",
      "네덜란드의 수도는 암스테르담입니다.\n"
     ]
    }
   ],
   "source": [
    "generate_output = gpt41_chain.generate(input_list)\n",
    "#generate_output.generations\n",
    "#generate_output.llm_output\n",
    "\n",
    "# 답변 출력\n",
    "for gen in generate_output.generations:\n",
    "    print(gen[0].text.strip())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
