{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 랭체인 주요기능 \n",
    "- 문맥 인식: 언어 모델과 다양한 문맥 소스(프롬프트 지시, 예제, 응답의 근거 내용 등)를 연동하며, 사용자의 문맥을 정확히 이해합니다.\n",
    "- 추론 능력: 제공된 문맥에 기반하여 어떤 대답을 할지, 또는 어떠한 액션을 취할지에 대한 추론이 가능합니다.\n",
    "- 구성 요소: 사용자는 언어 모델과의 상호작용을 위해 다양한 구성 요소와 추상화를 활용할 수 있습니다. 이러한 구성 요소는 개별적으로, 또는 랭체인 프레임워크 내에서 모듈식으로 쉽게 활용할 수 있습니다.\n",
    "- 사용 준비된 체인: 특정 고수준 작업을 수행하기 위해 미리 조립된 구성 요소의 패키지입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install openai langchain dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gpt-4-0613\n",
      "gpt-4\n",
      "gpt-3.5-turbo\n",
      "gpt-4o-audio-preview-2025-06-03\n",
      "gpt-4.1-nano\n",
      "gpt-image-1\n",
      "codex-mini-latest\n",
      "gpt-4o-realtime-preview-2025-06-03\n",
      "davinci-002\n",
      "babbage-002\n",
      "gpt-3.5-turbo-instruct\n",
      "gpt-3.5-turbo-instruct-0914\n",
      "dall-e-3\n",
      "dall-e-2\n",
      "gpt-4-1106-preview\n",
      "gpt-3.5-turbo-1106\n",
      "tts-1-hd\n",
      "tts-1-1106\n",
      "tts-1-hd-1106\n",
      "text-embedding-3-small\n",
      "text-embedding-3-large\n",
      "gpt-4-0125-preview\n",
      "gpt-4-turbo-preview\n",
      "gpt-3.5-turbo-0125\n",
      "gpt-4-turbo\n",
      "gpt-4-turbo-2024-04-09\n",
      "gpt-4o\n",
      "gpt-4o-2024-05-13\n",
      "gpt-4o-mini-2024-07-18\n",
      "gpt-4o-mini\n",
      "gpt-4o-2024-08-06\n",
      "chatgpt-4o-latest\n",
      "o1-preview-2024-09-12\n",
      "o1-preview\n",
      "o1-mini-2024-09-12\n",
      "o1-mini\n",
      "gpt-4o-realtime-preview-2024-10-01\n",
      "gpt-4o-audio-preview-2024-10-01\n",
      "gpt-4o-audio-preview\n",
      "gpt-4o-realtime-preview\n",
      "omni-moderation-latest\n",
      "omni-moderation-2024-09-26\n",
      "gpt-4o-realtime-preview-2024-12-17\n",
      "gpt-4o-audio-preview-2024-12-17\n",
      "gpt-4o-mini-realtime-preview-2024-12-17\n",
      "gpt-4o-mini-audio-preview-2024-12-17\n",
      "o1-2024-12-17\n",
      "o1\n",
      "gpt-4o-mini-realtime-preview\n",
      "gpt-4o-mini-audio-preview\n",
      "o3-mini\n",
      "o3-mini-2025-01-31\n",
      "gpt-4o-2024-11-20\n",
      "gpt-4.5-preview\n",
      "gpt-4.5-preview-2025-02-27\n",
      "gpt-4o-search-preview-2025-03-11\n",
      "gpt-4o-search-preview\n",
      "gpt-4o-mini-search-preview-2025-03-11\n",
      "gpt-4o-mini-search-preview\n",
      "gpt-4o-transcribe\n",
      "gpt-4o-mini-transcribe\n",
      "o1-pro-2025-03-19\n",
      "o1-pro\n",
      "gpt-4o-mini-tts\n",
      "o4-mini-2025-04-16\n",
      "o4-mini\n",
      "gpt-4.1-2025-04-14\n",
      "gpt-4.1\n",
      "gpt-4.1-mini-2025-04-14\n",
      "gpt-4.1-mini\n",
      "gpt-4.1-nano-2025-04-14\n",
      "gpt-3.5-turbo-16k\n",
      "tts-1\n",
      "whisper-1\n",
      "text-embedding-ada-002\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import openai\n",
    "\n",
    "load_dotenv('../.env')  # .env 파일의 환경변수 로드\n",
    "api_token = os.environ.get(\"OPENAI_API_KEY\")\n",
    "\n",
    "# openai 버전이 1.x.x 이하일경우 \n",
    "\"\"\"\n",
    "openai.api_key = api_token\n",
    "\n",
    "models = openai.Model.list()\n",
    "for model in models['data']:\n",
    "    print(model.id)\n",
    "\"\"\"\n",
    "\n",
    "# openai 버전이 1.x.x 이상일경우 \n",
    "client = openai.OpenAI(api_key=api_token)\n",
    "\n",
    "models = client.models.list()\n",
    "for model in models.data:\n",
    "    print(model.id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[작업시작] 2025-06-14 15:42:48\n",
      "이작업은 1 초 뒤 종료됩니다.\n",
      "[작업종료] 2025-06-14 15:42:49\n",
      "작업이 끝나습니다.\n",
      "[작업시작] 2025-06-14 15:42:49\n",
      "이작업은 2 초 뒤 종료됩니다.\n",
      "[작업종료] 2025-06-14 15:42:51\n",
      "작업이 끝나습니다.\n",
      "[작업시작] 2025-06-14 15:42:51\n",
      "이작업은 3 초 뒤 종료됩니다.\n",
      "[작업종료] 2025-06-14 15:42:54\n",
      "작업이 끝나습니다.\n"
     ]
    }
   ],
   "source": [
    "# 동기식 작업 \n",
    "import time\n",
    "import datetime\n",
    "\n",
    "def task(seconds) :\n",
    "    print(f'[작업시작] {datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")}')\n",
    "    print(f'이작업은 {seconds} 초 뒤 종료됩니다.')\n",
    "    time.sleep(seconds)\n",
    "    print(f'[작업종료] {datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")}')\n",
    "    print(f'작업이 끝나습니다.')\n",
    "\n",
    "def main() :\n",
    "    task(1)\n",
    "    task(2)\n",
    "    task(3)\n",
    "\n",
    "if __name__ == '__main__' :\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[작업시작] 2025-06-14 15:42:48\n",
      "이작업은 1 초 뒤 종료됩니다.\n",
      "[작업종료] 2025-06-14 15:42:49\n",
      "작업이 끝나습니다.\n",
      "[작업시작] 2025-06-14 15:42:49\n",
      "이작업은 2 초 뒤 종료됩니다.\n",
      "[작업종료] 2025-06-14 15:42:51\n",
      "작업이 끝나습니다.\n",
      "[작업시작] 2025-06-14 15:42:51\n",
      "이작업은 3 초 뒤 종료됩니다.\n",
      "[작업종료] 2025-06-14 15:42:54\n",
      "작업이 끝나습니다.\n"
     ]
    }
   ],
   "source": [
    "# 동기식 작업 \n",
    "import time\n",
    "import datetime\n",
    "\n",
    "def task(seconds) :\n",
    "    print(f'[작업시작] {datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")}')\n",
    "    print(f'이작업은 {seconds} 초 뒤 종료됩니다.')\n",
    "    time.sleep(seconds)\n",
    "    print(f'[작업종료] {datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")}')\n",
    "    print(f'작업이 끝나습니다.')\n",
    "\n",
    "def main() :\n",
    "    task(1)\n",
    "    task(2)\n",
    "    task(3)\n",
    "\n",
    "if __name__ == '__main__' :\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0, max_tokens=100)\n",
    "question = \"대한민국의 수도는 뭐야?\"\n",
    "print(f'{question} 에 대한 답변 : {llm.predict(question)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* PromptTemplate  \n",
    "사용자의 입력 변수를 사용하여 완전한 프롬프트 문자열을 만드는 데 사용되는 템플릿입니다  \n",
    "사용법 :  \n",
    "template: 템플릿 문자열입니다. 이 문자열 내에서 중괄호 {}는 변수를 나타냅니다.  \n",
    "input_variables: 중괄호 안에 들어갈 변수의 이름을 리스트로 정의합니다.  \n",
    "\n",
    "* input_variables  \n",
    "input_variables는 PromptTemplate에서 사용되는 변수의 이름을 정의하는 리스트입니다.  \n",
    "사용법: 리스트 형식으로 변수 이름을 정의합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "\n",
    "template = '{country}의 수도는 뭐야?'\n",
    "prompt = PromptTemplate(template=template, input_variables=['country'])\n",
    "chain = LLMChain(llm=llm, prompt=prompt)\n",
    "print(chain.run(country='대한민국'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LLMChain 객체\n",
    "LLMChain은 특정 PromptTemplate와 연결된 체인 객체를 생성합니다  \n",
    "\n",
    "사용법  \n",
    "- prompt: 앞서 정의한 PromptTemplate 객체를 사용합니다.\n",
    "- llm: 언어 모델을 나타내며, 이 예시에서는 이미 어딘가에서 정의된 것으로 보입니다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
